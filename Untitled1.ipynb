{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from scipy.signal import decimate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPool1D, GlobalAvgPool1D, Dropout, BatchNormalization, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filename(fname, string):   \n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':        \n",
    "        file_name = string + file_name\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_file(name, path):\n",
    "    _, b = wavfile.read(path + name)\n",
    "    assert _ == SAMPLE_RATE\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_to_length(arr, length):\n",
    "    \"\"\"Repeats the numpy 1D array to given length, and makes datatype float\"\"\"\n",
    "    result = np.empty((length, ), dtype = 'float32')\n",
    "    l = len(arr)\n",
    "    pos = 0\n",
    "    while pos + l <= length:\n",
    "        result[pos:pos+l] = arr\n",
    "        pos += l\n",
    "    if pos < length:\n",
    "        result[pos:length] = arr[:length-pos]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>sublabel</th>\n",
       "      <th>time_series</th>\n",
       "      <th>len_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>artifact__201012172012.wav</td>\n",
       "      <td>artifact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1.0, -3.0, -1.0, -7.0, -9.0, -2.0, -6.0, -5.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>artifact__201105040918.wav</td>\n",
       "      <td>artifact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-2.0, 3.0, -4.0, 4.0, -3.0, 2.0, -1.0, 0.0, 0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>artifact__201105041959.wav</td>\n",
       "      <td>artifact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6.0, -4.0, -9.0, -1.0, -4.0, 1.0, -5.0, 2.0, ...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>artifact__201105051017.wav</td>\n",
       "      <td>artifact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-85.0, -198.0, -214.0, -173.0, -177.0, -206.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>artifact__201105060108.wav</td>\n",
       "      <td>artifact</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[53.0, -35.0, 47.0, 170.0, 340.0, 436.0, 535.0...</td>\n",
       "      <td>396900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset                       fname     label  sublabel  \\\n",
       "0       a  artifact__201012172012.wav  artifact       NaN   \n",
       "1       a  artifact__201105040918.wav  artifact       NaN   \n",
       "2       a  artifact__201105041959.wav  artifact       NaN   \n",
       "3       a  artifact__201105051017.wav  artifact       NaN   \n",
       "4       a  artifact__201105060108.wav  artifact       NaN   \n",
       "\n",
       "                                         time_series  len_series  \n",
       "0  [1.0, -3.0, -1.0, -7.0, -9.0, -2.0, -6.0, -5.0...      396900  \n",
       "1  [-2.0, 3.0, -4.0, 4.0, -3.0, 2.0, -1.0, 0.0, 0...      396900  \n",
       "2  [6.0, -4.0, -9.0, -1.0, -4.0, 1.0, -5.0, 2.0, ...      396900  \n",
       "3  [-85.0, -198.0, -214.0, -173.0, -177.0, -206.0...      396900  \n",
       "4  [53.0, -35.0, 47.0, 170.0, 340.0, 436.0, 535.0...      396900  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('set_a.csv')\n",
    "df['fname'] = df['fname'].apply(clean_filename, string='Aunlabelledtest')\n",
    "df['label'] = df['label'].fillna('unclassified')\n",
    "df['time_series'] = df['fname'].apply(load_wav_file,path='set_a/')\n",
    "df['len_series'] = df['time_series'].apply(len)\n",
    "MAX_LEN = max(df['len_series'])\n",
    "df['time_series'] = df['time_series'].apply(repeat_to_length, length=MAX_LEN)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.stack(df['time_series'].values, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels =[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "             0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1,\n",
    "             1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, \n",
    "             2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n",
    "             2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, \n",
    "             1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, \n",
    "             0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, \n",
    "             1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "new_labels = np.array(new_labels, dtype='int')\n",
    "y_data = np_utils.to_categorical(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, train_filenames, test_filenames = \\\n",
    "    train_test_split(x_data, y_data, df['fname'].values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 8, axis=1, zero_phase=True)\n",
    "x_train = decimate(x_train, 4, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 8, axis=1, zero_phase=True)\n",
    "x_test = decimate(x_test, 4, axis=1, zero_phase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / np.std(x_train, axis=1).reshape(-1,1)\n",
    "x_test = x_test / np.std(x_test, axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:,:,np.newaxis]\n",
    "x_test = x_test[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n",
    "                input_shape = x_train.shape[1:],\n",
    "                kernel_regularizer = l2(0.025)))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=4, kernel_size=9, activation='relu',\n",
    "                kernel_regularizer = l2(0.05)))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=8, kernel_size=9, activation='relu',\n",
    "                 kernel_regularizer = l2(0.1)))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=16, kernel_size=9, activation='relu'))\n",
    "model.add(MaxPool1D(strides=4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(GlobalAvgPool1D())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_train, y_train, batch_size):\n",
    "    \"\"\"\n",
    "    Rotates the time series randomly in time\n",
    "    \"\"\"\n",
    "    x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32')\n",
    "    y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32')\n",
    "    full_idx = range(x_train.shape[0])\n",
    "    \n",
    "    while True:\n",
    "        batch_idx = np.random.choice(full_idx, batch_size)\n",
    "        x_batch = x_train[batch_idx]\n",
    "        y_batch = y_train[batch_idx]\n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            sz = np.random.randint(x_batch.shape[1])\n",
    "            x_batch[i] = np.roll(x_batch[i], sz, axis = 0)\n",
    "     \n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_saver = ModelCheckpoint('set_a_weights.h5', monitor='val_loss', \n",
    "                               save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.8**x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 43s - loss: 1.8950 - acc: 0.4661 - val_loss: 1.1237 - val_acc: 0.7955\n",
      "Epoch 2/25\n",
      " - 12s - loss: 1.2013 - acc: 0.6255 - val_loss: 0.7994 - val_acc: 0.9318\n",
      "Epoch 3/25\n",
      " - 11s - loss: 0.9721 - acc: 0.6761 - val_loss: 0.6064 - val_acc: 0.9318\n",
      "Epoch 4/25\n",
      " - 11s - loss: 0.8263 - acc: 0.7157 - val_loss: 0.4632 - val_acc: 0.9545\n",
      "Epoch 5/25\n",
      " - 11s - loss: 0.7595 - acc: 0.7369 - val_loss: 0.4191 - val_acc: 0.9318\n",
      "Epoch 6/25\n",
      " - 11s - loss: 0.6988 - acc: 0.7532 - val_loss: 0.4330 - val_acc: 0.9091\n",
      "Epoch 7/25\n",
      " - 11s - loss: 0.6608 - acc: 0.7720 - val_loss: 0.4120 - val_acc: 0.9318\n",
      "Epoch 8/25\n",
      " - 11s - loss: 0.6304 - acc: 0.7906 - val_loss: 0.3837 - val_acc: 0.9091\n",
      "Epoch 9/25\n",
      " - 11s - loss: 0.5920 - acc: 0.8091 - val_loss: 0.3494 - val_acc: 0.9318\n",
      "Epoch 10/25\n",
      " - 11s - loss: 0.5727 - acc: 0.8157 - val_loss: 0.3584 - val_acc: 0.9318\n",
      "Epoch 11/25\n",
      " - 12s - loss: 0.5440 - acc: 0.8275 - val_loss: 0.3165 - val_acc: 0.9545\n",
      "Epoch 12/25\n",
      " - 12s - loss: 0.5555 - acc: 0.8183 - val_loss: 0.3153 - val_acc: 0.9545\n",
      "Epoch 13/25\n",
      " - 11s - loss: 0.5549 - acc: 0.8221 - val_loss: 0.3204 - val_acc: 0.9545\n",
      "Epoch 14/25\n",
      " - 11s - loss: 0.5264 - acc: 0.8326 - val_loss: 0.3172 - val_acc: 0.9545\n",
      "Epoch 15/25\n",
      " - 11s - loss: 0.5498 - acc: 0.8240 - val_loss: 0.3081 - val_acc: 0.9545\n",
      "Epoch 16/25\n",
      " - 11s - loss: 0.5232 - acc: 0.8314 - val_loss: 0.3222 - val_acc: 0.9545\n",
      "Epoch 17/25\n",
      " - 11s - loss: 0.5148 - acc: 0.8369 - val_loss: 0.3213 - val_acc: 0.9318\n",
      "Epoch 18/25\n",
      " - 11s - loss: 0.5268 - acc: 0.8300 - val_loss: 0.3170 - val_acc: 0.9318\n",
      "Epoch 19/25\n",
      " - 12s - loss: 0.5386 - acc: 0.8289 - val_loss: 0.3206 - val_acc: 0.9318\n",
      "Epoch 20/25\n",
      " - 12s - loss: 0.5149 - acc: 0.8389 - val_loss: 0.3101 - val_acc: 0.9545\n",
      "Epoch 21/25\n",
      " - 11s - loss: 0.5147 - acc: 0.8361 - val_loss: 0.3101 - val_acc: 0.9318\n",
      "Epoch 22/25\n",
      " - 11s - loss: 0.5094 - acc: 0.8400 - val_loss: 0.3092 - val_acc: 0.9318\n",
      "Epoch 23/25\n",
      " - 11s - loss: 0.5055 - acc: 0.8407 - val_loss: 0.3091 - val_acc: 0.9318\n",
      "Epoch 24/25\n",
      " - 11s - loss: 0.5202 - acc: 0.8315 - val_loss: 0.3127 - val_acc: 0.9318\n",
      "Epoch 25/25\n",
      " - 11s - loss: 0.5294 - acc: 0.8334 - val_loss: 0.3152 - val_acc: 0.9318\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(batch_generator(x_train, y_train, 8),\n",
    "                   epochs=25, steps_per_epoch=1000,\n",
    "                   validation_data=(x_test, y_test),\n",
    "                   callbacks=[weight_saver, annealer],\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0, 2, 2,\n",
       "       2, 0, 2, 0, 0, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,b = wavfile.read('microphone-results.wav')\n",
    "SAMPLE_RATE = 44100\n",
    "assert _ == SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b[:396900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 396900)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(b)\n",
    "value = repeat_to_length(b,length)\n",
    "value = np.array([value])\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\signal\\signaltools.py:3463: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return y[sl]\n"
     ]
    }
   ],
   "source": [
    "value = decimate(value, 8, axis=1, zero_phase=True)\n",
    "value = decimate(value, 8, axis=1, zero_phase=True)\n",
    "value = decimate(value, 4, axis=1, zero_phase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1551)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = value / np.std(value, axis=1).reshape(-1,1)\n",
    "value = value[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-11aae03812d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y_new = model.predict(value)\n",
    "new_pred = np.argmax(y_new,axis =1)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9e18c434035e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_new' is not defined"
     ]
    }
   ],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel = (3,3),activation = 'relu',input = (50,50,3)))\n",
    "model.add(Conv2D(64,kernel = (3,3),activation = 'relu'))\n",
    "model.add(MaxPooling(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel=(3,3)),acivation = 'relu')\n",
    "model.add(Dropout(0.25))\n",
    "model.add(flatten())\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentrophy',optimizer='adam',metrices = ['accuracy'])\n",
    "model.fit(x_train,y_train,epochs = 25,verbose = 1,validation_data = (x_test,y_test))\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
